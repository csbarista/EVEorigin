{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[10, 11, 12, 13, 14],\n",
    "        [20, 22, 23, 24, 25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = {'position': torch.tensor([10])}\n",
    "frame2 = {'position': torch.tensor([11])}\n",
    "frame3 = {'position': torch.tensor([12])}\n",
    "frame4 = {'position': torch.tensor([13])}\n",
    "frame5 = {'position': torch.tensor([14])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dicts = [frame1, frame2, frame3, frame4, frame5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整合后的位置预测：\n",
      "tensor([[10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "full_intermediate_dict = {}\n",
    "sequence_len = len(intermediate_dicts)\n",
    "for k in intermediate_dicts[0].keys():\n",
    "    if not isinstance(intermediate_dicts[0][k], torch.Tensor):\n",
    "        continue\n",
    "    full_intermediate_dict[k] = torch.stack([\n",
    "        intermediate_dicts[i][k] for i in range(sequence_len)\n",
    "    ], axis=1)\n",
    "\n",
    "# 输出整合后的结果\n",
    "print(\"整合后的位置预测：\")\n",
    "print(full_intermediate_dict['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [0.1491, 0.1900, 0.2088, 0.2143, 0.2181, 0.2237, 0.2267, 0.2249, 0.2216,\n",
    "         0.2282, 0.2195, 0.2196, 0.2234, 0.2228, 0.2216, 0.2188, 0.2168, 0.2197,\n",
    "         0.2157, 0.2120, 0.2196, 0.2211, 0.2214, 0.2182, 0.2199, 0.2236, 0.2189,\n",
    "         0.2147, 0.2181, 0.2190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [2.1951, 2.2102, 2.1931, 2.2016, 2.1951, 2.1800, 2.1741, 2.1668, 2.1713,\n",
    "         2.1809, 2.2207, 2.2476, 2.2839, 2.3140, 2.3206, 2.2835, 2.2730, 2.2427,\n",
    "         2.2318, 2.2511, 2.3113, 2.3428, 2.3714, 2.3877, 2.4051, 2.4290, 2.4557,\n",
    "         2.4880, 2.5195, 2.5467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = [2.1951, 2.2102, 2.1931, 2.2016, 2.1951, 2.1800, 2.1741, 2.1668, 2.1713,\n",
    "         2.1809, 2.2207, 2.2476, 2.2839, 2.3140, 2.3206, 2.2835, 2.2730, 2.2427,\n",
    "         2.2318, 2.2511, 2.3113, 2.3428, 2.3714, 2.3877, 2.4051, 2.4290, 2.4557,\n",
    "         2.4880, 2.5195, 2.5467]\n",
    "for id, x in enumerate(x1):\n",
    "    x3[id] = abs(x2[id] - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0460000000000003,\n",
       " 2.0202,\n",
       " 1.9842999999999997,\n",
       " 1.9873,\n",
       " 1.977,\n",
       " 1.9563000000000001,\n",
       " 1.9474,\n",
       " 1.9419,\n",
       " 1.9497,\n",
       " 1.9526999999999999,\n",
       " 2.0012,\n",
       " 2.028,\n",
       " 2.0605,\n",
       " 2.0912,\n",
       " 2.099,\n",
       " 2.0647,\n",
       " 2.0562,\n",
       " 2.023,\n",
       " 2.0161,\n",
       " 2.0391,\n",
       " 2.0917000000000003,\n",
       " 2.1217,\n",
       " 2.15,\n",
       " 2.1695,\n",
       " 2.1852,\n",
       " 2.2054,\n",
       " 2.2368,\n",
       " 2.2733,\n",
       " 2.3013999999999997,\n",
       " 2.3277]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0768166666666668"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for x in x3:\n",
    "    sum += x\n",
    "sum / 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([[0.1491, 0.1900, 0.2088, 0.2143, 0.2181, 0.2237, 0.2267, 0.2249, 0.2216,\n",
    "         0.2282, 0.2195, 0.2196, 0.2234, 0.2228, 0.2216, 0.2188, 0.2168, 0.2197,\n",
    "         0.2157, 0.2120, 0.2196, 0.2211, 0.2214, 0.2182, 0.2199, 0.2236, 0.2189,\n",
    "         0.2147, 0.2181, 0.2190],\n",
    "        [0.1492, 0.1825, 0.2004, 0.2092, 0.2128, 0.2142, 0.2130, 0.2188, 0.2232,\n",
    "         0.2237, 0.2230, 0.2207, 0.2192, 0.2189, 0.2171, 0.2149, 0.2155, 0.2174,\n",
    "         0.2176, 0.2187, 0.2188, 0.2213, 0.2185, 0.2147, 0.2145, 0.2123, 0.2153,\n",
    "         0.2181, 0.2157, 0.2171],\n",
    "        [0.1464, 0.1851, 0.2050, 0.2160, 0.2183, 0.2167, 0.2175, 0.2150, 0.2146,\n",
    "         0.2178, 0.2140, 0.2157, 0.2183, 0.2199, 0.2205, 0.2209, 0.2248, 0.2226,\n",
    "         0.2239, 0.2230, 0.2168, 0.2233, 0.2245, 0.2219, 0.2261, 0.2243, 0.2198,\n",
    "         0.2242, 0.2246, 0.2244],\n",
    "        [0.1456, 0.1730, 0.1936, 0.1994, 0.2004, 0.2052, 0.2102, 0.2089, 0.2067,\n",
    "         0.2093, 0.2081, 0.2079, 0.2074, 0.2084, 0.2125, 0.2085, 0.2080, 0.2102,\n",
    "         0.2106, 0.2095, 0.2130, 0.2092, 0.2073, 0.2102, 0.2094, 0.2101, 0.2121,\n",
    "         0.2099, 0.2095, 0.2092],\n",
    "        [0.1431, 0.1748, 0.1886, 0.1995, 0.2048, 0.2018, 0.2003, 0.2050, 0.2089,\n",
    "         0.2091, 0.2107, 0.2095, 0.2096, 0.2109, 0.2096, 0.2082, 0.2034, 0.2117,\n",
    "         0.2091, 0.2094, 0.2129, 0.2104, 0.2114, 0.2083, 0.2106, 0.2171, 0.2159,\n",
    "         0.2132, 0.2147, 0.2131],\n",
    "        [0.1470, 0.1825, 0.1976, 0.2090, 0.2113, 0.2112, 0.2113, 0.2110, 0.2146,\n",
    "         0.2144, 0.2146, 0.2162, 0.2147, 0.2172, 0.2162, 0.2109, 0.2145, 0.2142,\n",
    "         0.2111, 0.2141, 0.2136, 0.2141, 0.2155, 0.2191, 0.2186, 0.2177, 0.2176,\n",
    "         0.2203, 0.2192, 0.2140],\n",
    "        [0.1428, 0.1764, 0.1902, 0.1991, 0.2047, 0.2060, 0.2085, 0.2079, 0.2096,\n",
    "         0.2075, 0.2059, 0.2045, 0.2038, 0.2087, 0.2071, 0.2081, 0.2053, 0.2049,\n",
    "         0.2037, 0.2034, 0.2050, 0.2073, 0.2073, 0.2093, 0.2083, 0.2073, 0.2074,\n",
    "         0.2061, 0.2064, 0.2057],\n",
    "        [0.1524, 0.1871, 0.2062, 0.2115, 0.2150, 0.2181, 0.2173, 0.2177, 0.2206,\n",
    "         0.2179, 0.2214, 0.2201, 0.2175, 0.2168, 0.2203, 0.2232, 0.2219, 0.2212,\n",
    "         0.2190, 0.2221, 0.2206, 0.2200, 0.2209, 0.2185, 0.2187, 0.2217, 0.2203,\n",
    "         0.2189, 0.2177, 0.2193],\n",
    "        [0.1454, 0.1766, 0.1938, 0.1993, 0.2059, 0.2095, 0.2088, 0.2103, 0.2102,\n",
    "         0.2102, 0.2100, 0.2098, 0.2097, 0.2091, 0.2106, 0.2131, 0.2139, 0.2157,\n",
    "         0.2171, 0.2118, 0.2092, 0.2130, 0.2079, 0.2067, 0.2059, 0.2043, 0.2046,\n",
    "         0.2052, 0.2052, 0.2055],\n",
    "        [0.1484, 0.1833, 0.1984, 0.2047, 0.2074, 0.2102, 0.2135, 0.2221, 0.2198,\n",
    "         0.2202, 0.2231, 0.2248, 0.2204, 0.2221, 0.2233, 0.2195, 0.2224, 0.2225,\n",
    "         0.2224, 0.2225, 0.2199, 0.2211, 0.2235, 0.2228, 0.2192, 0.2230, 0.2240,\n",
    "         0.2258, 0.2197, 0.2214],\n",
    "        [0.1478, 0.1837, 0.2045, 0.2149, 0.2177, 0.2160, 0.2117, 0.2148, 0.2146,\n",
    "         0.2172, 0.2154, 0.2166, 0.2156, 0.2149, 0.2124, 0.2137, 0.2140, 0.2150,\n",
    "         0.2193, 0.2215, 0.2203, 0.2192, 0.2171, 0.2142, 0.2153, 0.2135, 0.2118,\n",
    "         0.2113, 0.2165, 0.2166],\n",
    "        [0.1478, 0.1779, 0.1985, 0.2050, 0.2144, 0.2134, 0.2189, 0.2155, 0.2124,\n",
    "         0.2101, 0.2090, 0.2152, 0.2182, 0.2151, 0.2185, 0.2172, 0.2161, 0.2154,\n",
    "         0.2181, 0.2223, 0.2145, 0.2114, 0.2148, 0.2128, 0.2149, 0.2130, 0.2187,\n",
    "         0.2167, 0.2172, 0.2189],\n",
    "        [0.1480, 0.1785, 0.1978, 0.2039, 0.2061, 0.2114, 0.2165, 0.2159, 0.2154,\n",
    "         0.2129, 0.2083, 0.2078, 0.2087, 0.2076, 0.2075, 0.2097, 0.2116, 0.2080,\n",
    "         0.2092, 0.2093, 0.2161, 0.2150, 0.2140, 0.2148, 0.2123, 0.2163, 0.2158,\n",
    "         0.2133, 0.2160, 0.2142],\n",
    "        [0.1479, 0.1861, 0.2062, 0.2142, 0.2179, 0.2183, 0.2192, 0.2144, 0.2142,\n",
    "         0.2160, 0.2205, 0.2197, 0.2170, 0.2213, 0.2198, 0.2212, 0.2188, 0.2183,\n",
    "         0.2212, 0.2257, 0.2214, 0.2228, 0.2206, 0.2197, 0.2216, 0.2203, 0.2193,\n",
    "         0.2181, 0.2134, 0.2121],\n",
    "        [0.1445, 0.1785, 0.1925, 0.2040, 0.2067, 0.2086, 0.2093, 0.2113, 0.2103,\n",
    "         0.2123, 0.2138, 0.2106, 0.2155, 0.2116, 0.2150, 0.2142, 0.2158, 0.2140,\n",
    "         0.2165, 0.2134, 0.2123, 0.2094, 0.2094, 0.2124, 0.2110, 0.2144, 0.2181,\n",
    "         0.2167, 0.2184, 0.2188],\n",
    "        [0.1505, 0.1851, 0.2032, 0.2132, 0.2179, 0.2191, 0.2222, 0.2241, 0.2239,\n",
    "         0.2224, 0.2204, 0.2178, 0.2209, 0.2258, 0.2237, 0.2208, 0.2243, 0.2248,\n",
    "         0.2239, 0.2248, 0.2254, 0.2260, 0.2231, 0.2233, 0.2232, 0.2218, 0.2217,\n",
    "         0.2227, 0.2245, 0.2256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.tensor([[2.1951, 2.2102, 2.1931, 2.2016, 2.1951, 2.1800, 2.1741, 2.1668, 2.1713,\n",
    "         2.1809, 2.2207, 2.2476, 2.2839, 2.3140, 2.3206, 2.2835, 2.2730, 2.2427,\n",
    "         2.2318, 2.2511, 2.3113, 2.3428, 2.3714, 2.3877, 2.4051, 2.4290, 2.4557,\n",
    "         2.4880, 2.5195, 2.5467],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000],\n",
    "        [3.3559, 3.3533, 3.2682, 3.2154, 3.1822, 0.0000, 3.2546, 3.2792, 3.2833,\n",
    "         3.2008, 3.1639, 3.1719, 3.2057, 3.2466, 3.2901, 3.3145, 3.3228, 3.3673,\n",
    "         3.3963, 3.4029, 3.3550, 3.3064, 0.0000, 3.2687, 3.2913, 3.3202, 3.3607,\n",
    "         3.3741, 3.3803, 3.3377],\n",
    "        [3.1579, 0.0000, 0.0000, 3.1578, 3.0529, 2.9877, 2.9473, 2.8610, 2.7979,\n",
    "         2.7693, 2.7395, 2.7281, 2.7117, 2.7022, 2.7266, 2.8199, 2.8468, 0.0000,\n",
    "         0.0000, 2.9093, 2.9304, 2.9988, 3.0413, 2.9687, 2.8749, 2.8062, 2.7639,\n",
    "         2.7393, 2.7386, 2.7360],\n",
    "        [2.4838, 2.4659, 2.4433, 2.4375, 2.4459, 2.4469, 2.4562, 2.4653, 2.4647,\n",
    "         2.4319, 2.3765, 2.3561, 2.3604, 2.3659, 0.0000, 0.0000, 2.3905, 2.4302,\n",
    "         2.5262, 2.5520, 2.4936, 2.4226, 2.3783, 2.3586, 2.3511, 2.3637, 2.3783,\n",
    "         2.3973, 2.4012, 2.3861],\n",
    "        [2.5308, 2.4761, 2.4616, 2.4245, 2.4334, 2.4478, 2.4628, 2.4700, 2.5016,\n",
    "         2.5348, 2.5878, 2.6046, 2.5950, 2.5857, 2.5837, 2.6019, 2.6681, 2.6602,\n",
    "         2.6387, 2.6190, 2.6186, 2.6117, 2.6103, 2.6278, 2.6280, 2.6086, 2.6008,\n",
    "         2.6116, 2.6178, 2.6225],\n",
    "        [3.5450, 3.5422, 0.0000, 3.3077, 3.6568, 3.6982, 3.7579, 3.7937, 3.7522,\n",
    "         3.6675, 3.6033, 3.5372, 0.0000, 3.4383, 3.4070, 3.4609, 3.5167, 3.5758,\n",
    "         3.5550, 3.5000, 3.4769, 3.4865, 3.5276, 3.5938, 3.6442, 3.6282, 3.5528,\n",
    "         3.4983, 3.4403, 3.3945],\n",
    "        [2.8876, 2.9017, 2.9177, 2.9467, 2.9540, 2.9438, 2.9386, 2.9316, 2.9043,\n",
    "         2.8953, 2.9078, 2.9258, 2.9396, 2.9616, 2.8093, 2.6559, 2.5435, 2.4659,\n",
    "         2.4099, 2.3741, 2.3461, 2.3418, 2.3593, 2.3851, 2.3782, 2.4041, 2.4466,\n",
    "         2.4795, 2.5202, 2.5317],\n",
    "        [2.7030, 2.7348, 2.7554, 2.7647, 2.7640, 2.7648, 2.7695, 2.7592, 2.7512,\n",
    "         2.7546, 2.7464, 2.7576, 2.7621, 2.7744, 2.7851, 2.7965, 2.8084, 2.8193,\n",
    "         2.8194, 2.8284, 2.8415, 2.8648, 2.8781, 2.8985, 2.8442, 2.7925, 2.7494,\n",
    "         2.7972, 2.7954, 2.8139],\n",
    "        [2.8050, 2.8158, 2.8150, 2.8079, 2.8172, 2.7942, 2.8152, 2.7968, 2.7956,\n",
    "         0.0000, 2.8077, 2.7396, 2.8080, 2.8840, 2.9096, 2.8986, 2.8466, 2.8067,\n",
    "         2.7602, 2.7422, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         2.8548, 2.8426, 2.8504],\n",
    "        [2.2902, 2.2779, 2.2805, 2.2925, 2.2894, 2.2933, 2.3048, 2.3262, 2.3340,\n",
    "         2.3343, 0.0000, 2.3336, 2.3754, 2.4038, 2.3990, 2.3383, 2.3204, 2.2980,\n",
    "         2.2967, 2.3031, 2.3287, 2.3533, 2.3551, 2.3379, 2.3630, 2.3760, 2.3795,\n",
    "         2.3622, 2.3704, 2.3726],\n",
    "        [2.7785, 2.8483, 2.8243, 2.9019, 0.0000, 2.7918, 2.8141, 2.8433, 2.8302,\n",
    "         2.7766, 2.7300, 2.7777, 2.7424, 2.7551, 2.7337, 2.7326, 2.7267, 2.7118,\n",
    "         2.7219, 2.7400, 2.7323, 2.7124, 2.7197, 2.7265, 2.7183, 2.7348, 2.7553,\n",
    "         2.7573, 2.7707, 2.7727],\n",
    "        [2.9644, 2.9641, 2.9728, 2.9789, 2.9711, 2.9704, 2.9926, 3.0297, 3.0778,\n",
    "         3.1156, 3.0991, 3.0975, 3.1122, 0.0000, 3.0760, 3.0887, 3.1044, 3.0360,\n",
    "         2.9861, 3.0188, 3.0686, 3.0130, 2.9482, 2.9084, 2.8463, 2.8058, 2.8043,\n",
    "         2.7858, 2.8135, 2.8698],\n",
    "        [3.2859, 3.2841, 3.2919, 3.3551, 3.3731, 3.3804, 3.3554, 3.3395, 3.2970,\n",
    "         3.2365, 3.1830, 3.1438, 3.1376, 3.1278, 3.1399, 3.1597, 3.1749, 3.1571,\n",
    "         3.1271, 3.1112, 3.1187, 3.1179, 3.1374, 3.1469, 3.1583, 3.1890, 3.2424,\n",
    "         3.2663, 3.2517, 3.2376],\n",
    "        [2.4432, 2.4889, 2.5098, 2.5002, 2.4653, 2.4156, 2.3787, 2.3425, 2.3399,\n",
    "         2.3624, 2.3731, 2.3800, 2.3741, 2.2900, 2.2082, 2.1255, 2.1098, 2.1220,\n",
    "         2.1600, 2.1929, 2.2178, 0.0000, 0.0000, 2.2247, 2.2429, 2.2743, 2.2918,\n",
    "         2.2876, 2.2599, 2.2473],\n",
    "        [2.3362, 2.3152, 2.3157, 2.3426, 2.3829, 2.3845, 2.3512, 2.3341, 2.3325,\n",
    "         2.3133, 2.3217, 2.3421, 2.3699, 2.3828, 2.3579, 2.3205, 2.2738, 2.2845,\n",
    "         2.3300, 2.3967, 2.4734, 2.5320, 2.5921, 2.6353, 2.6269, 2.5975, 2.5431,\n",
    "         2.5148, 2.4951, 2.4810]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.abs(x2 - x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0460, 2.0202, 1.9843, 1.9873, 1.9770, 1.9563, 1.9474, 1.9419, 1.9497,\n",
       "         1.9527, 2.0012, 2.0280, 2.0605, 2.0912, 2.0990, 2.0647, 2.0562, 2.0230,\n",
       "         2.0161, 2.0391, 2.0917, 2.1217, 2.1500, 2.1695, 2.1852, 2.2054, 2.2368,\n",
       "         2.2733, 2.3014, 2.3277],\n",
       "        [0.1492, 0.1825, 0.2004, 0.2092, 0.2128, 0.2142, 0.2130, 0.2188, 0.2232,\n",
       "         0.2237, 0.2230, 0.2207, 0.2192, 0.2189, 0.2171, 0.2149, 0.2155, 0.2174,\n",
       "         0.2176, 0.2187, 0.2188, 0.2213, 0.2185, 0.2147, 0.2145, 0.2123, 0.2153,\n",
       "         0.2181, 0.2157, 0.2171],\n",
       "        [3.2095, 3.1682, 3.0632, 2.9994, 2.9639, 0.2167, 3.0371, 3.0642, 3.0687,\n",
       "         2.9830, 2.9499, 2.9562, 2.9874, 3.0267, 3.0696, 3.0936, 3.0980, 3.1447,\n",
       "         3.1724, 3.1799, 3.1382, 3.0831, 0.2245, 3.0468, 3.0652, 3.0959, 3.1409,\n",
       "         3.1499, 3.1557, 3.1133],\n",
       "        [3.0123, 0.1730, 0.1936, 2.9584, 2.8525, 2.7825, 2.7371, 2.6521, 2.5912,\n",
       "         2.5600, 2.5314, 2.5202, 2.5043, 2.4938, 2.5141, 2.6114, 2.6388, 0.2102,\n",
       "         0.2106, 2.6998, 2.7174, 2.7896, 2.8340, 2.7585, 2.6655, 2.5961, 2.5518,\n",
       "         2.5294, 2.5291, 2.5268],\n",
       "        [2.3407, 2.2911, 2.2547, 2.2380, 2.2411, 2.2451, 2.2559, 2.2603, 2.2558,\n",
       "         2.2228, 2.1658, 2.1466, 2.1508, 2.1550, 0.2096, 0.2082, 2.1871, 2.2185,\n",
       "         2.3171, 2.3426, 2.2807, 2.2122, 2.1669, 2.1503, 2.1405, 2.1466, 2.1624,\n",
       "         2.1841, 2.1865, 2.1730],\n",
       "        [2.3838, 2.2936, 2.2640, 2.2155, 2.2221, 2.2366, 2.2515, 2.2590, 2.2870,\n",
       "         2.3204, 2.3732, 2.3884, 2.3803, 2.3685, 2.3675, 2.3910, 2.4536, 2.4460,\n",
       "         2.4276, 2.4049, 2.4050, 2.3976, 2.3948, 2.4087, 2.4094, 2.3909, 2.3832,\n",
       "         2.3913, 2.3986, 2.4085],\n",
       "        [3.4022, 3.3658, 0.1902, 3.1086, 3.4521, 3.4922, 3.5494, 3.5858, 3.5426,\n",
       "         3.4600, 3.3974, 3.3327, 0.2038, 3.2296, 3.1999, 3.2528, 3.3114, 3.3709,\n",
       "         3.3513, 3.2966, 3.2719, 3.2792, 3.3203, 3.3845, 3.4359, 3.4209, 3.3454,\n",
       "         3.2922, 3.2339, 3.1888],\n",
       "        [2.7352, 2.7146, 2.7115, 2.7352, 2.7390, 2.7257, 2.7213, 2.7139, 2.6837,\n",
       "         2.6774, 2.6864, 2.7057, 2.7221, 2.7448, 2.5890, 2.4327, 2.3216, 2.2447,\n",
       "         2.1909, 2.1520, 2.1255, 2.1218, 2.1384, 2.1666, 2.1595, 2.1824, 2.2263,\n",
       "         2.2606, 2.3025, 2.3124],\n",
       "        [2.5576, 2.5582, 2.5616, 2.5654, 2.5581, 2.5553, 2.5607, 2.5489, 2.5410,\n",
       "         2.5444, 2.5364, 2.5478, 2.5524, 2.5653, 2.5745, 2.5834, 2.5945, 2.6036,\n",
       "         2.6023, 2.6166, 2.6323, 2.6518, 2.6702, 2.6918, 2.6383, 2.5882, 2.5448,\n",
       "         2.5920, 2.5902, 2.6084],\n",
       "        [2.6566, 2.6325, 2.6166, 2.6032, 2.6098, 2.5840, 2.6017, 2.5747, 2.5758,\n",
       "         0.2202, 2.5846, 2.5148, 2.5876, 2.6619, 2.6863, 2.6791, 2.6242, 2.5842,\n",
       "         2.5378, 2.5197, 0.2199, 0.2211, 0.2235, 0.2228, 0.2192, 0.2230, 0.2240,\n",
       "         2.6290, 2.6229, 2.6290],\n",
       "        [2.1424, 2.0942, 2.0760, 2.0776, 2.0717, 2.0773, 2.0931, 2.1114, 2.1194,\n",
       "         2.1171, 0.2154, 2.1170, 2.1598, 2.1889, 2.1866, 2.1246, 2.1064, 2.0830,\n",
       "         2.0774, 2.0816, 2.1084, 2.1341, 2.1380, 2.1237, 2.1477, 2.1625, 2.1677,\n",
       "         2.1509, 2.1539, 2.1560],\n",
       "        [2.6307, 2.6704, 2.6258, 2.6969, 0.2144, 2.5784, 2.5952, 2.6278, 2.6178,\n",
       "         2.5665, 2.5210, 2.5625, 2.5242, 2.5400, 2.5152, 2.5154, 2.5106, 2.4964,\n",
       "         2.5038, 2.5177, 2.5178, 2.5010, 2.5049, 2.5137, 2.5034, 2.5218, 2.5366,\n",
       "         2.5406, 2.5535, 2.5538],\n",
       "        [2.8164, 2.7856, 2.7750, 2.7750, 2.7650, 2.7590, 2.7761, 2.8138, 2.8624,\n",
       "         2.9027, 2.8908, 2.8897, 2.9035, 0.2076, 2.8685, 2.8790, 2.8928, 2.8280,\n",
       "         2.7769, 2.8095, 2.8525, 2.7980, 2.7342, 2.6936, 2.6340, 2.5895, 2.5885,\n",
       "         2.5725, 2.5975, 2.6556],\n",
       "        [3.1380, 3.0980, 3.0857, 3.1409, 3.1552, 3.1621, 3.1362, 3.1251, 3.0828,\n",
       "         3.0205, 2.9625, 2.9241, 2.9206, 2.9065, 2.9201, 2.9385, 2.9561, 2.9388,\n",
       "         2.9059, 2.8855, 2.8973, 2.8951, 2.9168, 2.9272, 2.9367, 2.9687, 3.0231,\n",
       "         3.0482, 3.0383, 3.0255],\n",
       "        [2.2987, 2.3104, 2.3173, 2.2962, 2.2586, 2.2070, 2.1694, 2.1312, 2.1296,\n",
       "         2.1501, 2.1593, 2.1694, 2.1586, 2.0784, 1.9932, 1.9113, 1.8940, 1.9080,\n",
       "         1.9435, 1.9795, 2.0055, 0.2094, 0.2094, 2.0123, 2.0319, 2.0599, 2.0737,\n",
       "         2.0709, 2.0415, 2.0285],\n",
       "        [2.1857, 2.1301, 2.1125, 2.1294, 2.1650, 2.1654, 2.1290, 2.1100, 2.1086,\n",
       "         2.0909, 2.1013, 2.1243, 2.1490, 2.1570, 2.1342, 2.0997, 2.0495, 2.0597,\n",
       "         2.1061, 2.1719, 2.2480, 2.3060, 2.3690, 2.4120, 2.4037, 2.3757, 2.3214,\n",
       "         2.2921, 2.2706, 2.2554]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1095.1367)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3851781250000004"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1137.9988 / 16 / 30 + 1151.7722 / 16 / 30) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eve0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
